{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K37OeDTJ3pxa"
   },
   "source": [
    "# TRAINED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 16 12:57:25 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:0A:00.0  On |                  N/A |\r\n",
      "|  0%   48C    P8    15W / 250W |    265MiB / 11016MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1299      G   /usr/lib/xorg/Xorg                 35MiB |\r\n",
      "|    0   N/A  N/A     46804      G   /usr/lib/xorg/Xorg                 77MiB |\r\n",
      "|    0   N/A  N/A     47018      G   /usr/bin/gnome-shell              105MiB |\r\n",
      "|    0   N/A  N/A    200636      G   ...AAAAAAAAA= --shared-files       27MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pIsyfuy3vGR"
   },
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc, ndimage, signal\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "import ntpath\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from time import time\n",
    "import time as tm\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "1uktmmET3ydb",
    "outputId": "37c1ca89-b48d-4d2c-d539-39ed781054cd"
   },
   "outputs": [],
   "source": [
    "#Utilities\n",
    "import numpy as np\n",
    "import time\n",
    "import time as tm\n",
    "\n",
    "#Visualizers\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#Model\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from scipy import misc, ndimage, signal\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "import ntpath\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from time import time\n",
    "import time as tm\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Cross validation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    "\n",
    "#Yellowbric Class\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from yellowbrick.style import find_text_color\n",
    "from yellowbrick.style.palettes import color_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJuULHAA33om"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 30)\n"
     ]
    }
   ],
   "source": [
    "################################################## 30 SRM FILTERS\n",
    "srm_weights = np.load('./SRM_Kernels1.npy') \n",
    "biasSRM=numpy.ones(30)\n",
    "print (srm_weights.shape)\n",
    "################################################## TLU ACTIVATION FUNCTION\n",
    "T3 = 3;\n",
    "def Tanh3(x):\n",
    "    tanh3 = K.tanh(x)*T3\n",
    "    return tanh3\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBRAS_Net():\n",
    "    tf.keras.backend.clear_session()\n",
    "    #Inputs\n",
    "    inputs = tf.keras.Input(shape=(256,256,1), name=\"input_1\")\n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), padding='same', trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
    "    layers1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.DepthwiseConv2D(1)(layers1)\n",
    "    layers = tf.keras.layers.SeparableConv2D(30,(3,3), padding='same', activation=\"elu\",depth_multiplier=3)(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.DepthwiseConv2D(1)(layers)\n",
    "    layers = tf.keras.layers.SeparableConv2D(30,(3,3), padding='same', activation=\"elu\",depth_multiplier=3)(layers) \n",
    "    layers2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    skip1 =   tf.keras.layers.Add()([layers1, layers2])\n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(skip1) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 6\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    #Layer 7\n",
    "    layers = tf.keras.layers.Conv2D(60, (3,3), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(layers) \n",
    "    layers3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 8\n",
    "    layers = tf.keras.layers.DepthwiseConv2D(1)(layers3)\n",
    "    layers = tf.keras.layers.SeparableConv2D(60,(3,3), padding='same', activation=\"elu\",depth_multiplier=3)(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 9\n",
    "    layers = tf.keras.layers.DepthwiseConv2D(1)(layers)\n",
    "    layers = tf.keras.layers.SeparableConv2D(60,(3,3), padding='same', activation=\"elu\",depth_multiplier=3)(layers) \n",
    "    layers4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    skip2 =   tf.keras.layers.Add()([layers3, layers4])\n",
    "    #Layer 10\n",
    "    layers = tf.keras.layers.Conv2D(60, (3,3), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(skip2) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 11\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    #Layer 12\n",
    "    layers = tf.keras.layers.Conv2D(60, (3,3), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 13\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    #Layer 14\n",
    "    layers = tf.keras.layers.Conv2D(60, (3,3), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 15\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    #Layer 16\n",
    "    layers = tf.keras.layers.Conv2D(30, (1,1), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 17\n",
    "    layers = tf.keras.layers.Conv2D(2, (1,1), strides=(1,1), activation=\"elu\", padding='same', kernel_initializer='glorot_uniform')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    #Layer 18\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    #Layer 19\n",
    "    predictions = tf.keras.layers.Softmax(axis=1)(layers)\n",
    "    #Model generation\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    #Optimizer\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    print (\"Model GBRAS-Net Generated\")\n",
    "    #Model compilation\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE OF THE TRAINED MODELS ON TEST DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-UNIWARD 0.4bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image data and labels (20000, 256, 256, 1) (20000, 2)\n",
      "(8000, 256, 256, 1)\n",
      "(8000, 2)\n",
      "(2000, 256, 256, 1)\n",
      "(2000, 2)\n",
      "(10000, 256, 256, 1)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/S-UNIWARD/0.4bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
    "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
    "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3709 and Accuracy=0.8716\n"
     ]
    }
   ],
   "source": [
    "path_log = './Trained_Models' \n",
    "model_name = '/S-UNIWARD_0.4bpp.hdf5'\n",
    "model = tf.keras.models.load_model(path_log+model_name, custom_objects={'Tanh3':Tanh3}, compile=True)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test,verbose=0) \n",
    "print(f'Loss={loss:.4f} and Accuracy={accuracy:0.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-UNIWARD 0.2bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image data and labels (20000, 256, 256, 1) (20000, 2)\n",
      "(8000, 256, 256, 1)\n",
      "(8000, 2)\n",
      "(2000, 256, 256, 1)\n",
      "(2000, 2)\n",
      "(10000, 256, 256, 1)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/S-UNIWARD/0.2bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
    "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
    "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5492 and Accuracy=0.7365\n"
     ]
    }
   ],
   "source": [
    "path_log = './Trained_Models' \n",
    "model_name = '/S-UNIWARD_0.2bpp.hdf5'\n",
    "model = tf.keras.models.load_model(path_log+model_name, custom_objects={'Tanh3':Tanh3}, compile=True)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test,verbose=0) \n",
    "print(f'Loss={loss:.4f} and Accuracy={accuracy:0.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOW 0.2bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image data and labels (20000, 256, 256, 1) (20000, 2)\n",
      "(8000, 256, 256, 1)\n",
      "(8000, 2)\n",
      "(2000, 256, 256, 1)\n",
      "(2000, 2)\n",
      "(10000, 256, 256, 1)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/WOW/0.2bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
    "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
    "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5132 and Accuracy=0.8032\n"
     ]
    }
   ],
   "source": [
    "path_log = './Trained_Models' \n",
    "model_name = '/WOW_0.2bpp.hdf5'\n",
    "model = tf.keras.models.load_model(path_log+model_name, custom_objects={'Tanh3':Tanh3}, compile=True)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test,verbose=0) \n",
    "print(f'Loss={loss:.4f} and Accuracy={accuracy:0.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOW 0.4bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image data and labels (20000, 256, 256, 1) (20000, 2)\n",
      "(8000, 256, 256, 1)\n",
      "(8000, 2)\n",
      "(2000, 256, 256, 1)\n",
      "(2000, 2)\n",
      "(10000, 256, 256, 1)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/WOW/0.4bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
    "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
    "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3967 and Accuracy=0.8979\n"
     ]
    }
   ],
   "source": [
    "path_log = './Trained_Models' \n",
    "model_name = '/WOW_0.4bpp.hdf5'\n",
    "model = tf.keras.models.load_model(path_log+model_name, custom_objects={'Tanh3':Tanh3}, compile=True)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test,verbose=0) \n",
    "print(f'Loss={loss:.4f} and Accuracy={accuracy:0.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GRAFICOS_DL_METRICS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
